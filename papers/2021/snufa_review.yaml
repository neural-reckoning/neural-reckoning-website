selected: true
year: 2021
authors: Zenke F, BohtÃ© SM, Clopath C, ComÅŸa IM, GÃ¶ltz J, Maass W, Masquelier T, Naud
  R, Neftci EO, Petrovici MA, Scherr F, Goodman DFM
title: Visualizing a joint future of neuroscience and neuromorphic engineering
journal: Neuron
doi: 10.1016/j.neuron.2021.01.009
categories:
- Neuroscience
- Spiking
- Machine learning
- Plasticity
- Learning
- Neuroinformatics
urls:
- - Journal
  - https://doi.org/10.1016/j.neuron.2021.01.009
- - Preprint (PDF)
  - https://www.dropbox.com/s/942rf97l80wyya5/snufa-meeting-report.pdf?dl=1
- - Workshop
  - https://neural-reckoning.github.io/snn_workshop_2020/
- - Workshop talk recordings
  - https://www.youtube.com/playlist?list=PL09WqqDbQWHFvM9DFYkM_GfnrVnIdLRhy
- - Twitter
  - https://twitter.com/neuralreckoning/status/1362107086017036289
abstract: |-
  Recent research resolves the challenging problem of building biophysically plausible spiking neural models that
  are also capable of complex information processing. This advance creates new opportunities in neuroscience and
  neuromorphic engineering, which we discussed at an online focus meeting.
last_tweet_in_thread: '1362107103998062594'
twitter_thread: >
  <blockquote class="twitter-tweet" data-width="400" data-dnt="true"><p lang="en" dir="ltr">The spikes must flow!<br><br>I&#39;d love to announce a new paper with that title, but sadly the editors at Neuron changed it.<br><br>Still v happy this paper is out because there&#39;s a revolution taking place in spiking neural networks and I want everyone to know about it. ðŸ‘‡ðŸ§µ <a href="https://t.co/gXyEsrIJig">pic.twitter.com/gXyEsrIJig</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107086017036289?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Two of the things that make the brain interesting are (a) it is intelligent, it lets us make sense of very complex, noisy sensory data, (b) neurons use this super weird method of communicating. Now, for the first time, we can train spiking networks that can do hard tasks.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107089020219392?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">This is a game changer! We can finally begin to answer questions about how the brain uses patterns of spikes to compute in real-world situations. This is the question that got me into neuroscience in the first place!</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107092140703744?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">So what changed? Methods from ML let us train neural networks at much harder tasks than before, but this was limited to artificial NNs, not spiking. Over the last couple of years, a number of tricks have been found to make it work for general case spiking neurons.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107094464348160?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">The code is relatively easy to write, but it&#39;s still quite slow at the moment and can only be used for a few hundred neurons. But, this is changing rapidly and there are going to be exciting times ahead over the next few years.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107096913874947?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">So, go take a look at our paper. This link will work until April 8th as long as you turn off your ad blocker:<a href="https://t.co/Btrhf9MGp4">https://t.co/Btrhf9MGp4</a><br><br>After that, I&#39;ll keep this page up to date:<a href="https://t.co/mhBRunEpMb">https://t.co/mhBRunEpMb</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107098889412609?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">You can also take a look at recordings of the talks this review paper is based on here:<a href="https://t.co/sNMvHiZsI3">https://t.co/sNMvHiZsI3</a><br><br>It was based around a workshop we ran last summer, and we&#39;re planning to run that again this summer, this time with a challenge, so keep an eye out for that.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107101762506756?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Thanks for your attention, and to co-authors <a href="https://twitter.com/hisspikeness?ref_src=twsrc%5Etfw">@hisspikeness</a> <a href="https://twitter.com/SanderBohte?ref_src=twsrc%5Etfw">@SanderBohte</a> <a href="https://twitter.com/ClopathLab?ref_src=twsrc%5Etfw">@ClopathLab</a> <a href="https://twitter.com/astronomind?ref_src=twsrc%5Etfw">@astronomind</a> <a href="https://twitter.com/NeuroNaud?ref_src=twsrc%5Etfw">@NeuroNaud</a> <a href="https://twitter.com/virtualmind?ref_src=twsrc%5Etfw">@virtualmind</a> <a href="https://twitter.com/franz_scherr?ref_src=twsrc%5Etfw">@franz_scherr</a>  and others not on twitter. (End)</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1362107103998062594?ref_src=twsrc%5Etfw">February 17, 2021</a></blockquote>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>