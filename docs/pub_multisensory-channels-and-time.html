<!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
    <META http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />

    <!-- social media stuff -->
    <meta name="twitter:widgets:csp" content="on">
    <meta name="twitter:dnt" content="on">
    <meta name="description" content="Animals continuously combine information across sensory modalities and time, and use these combined signals to guide their behaviour. Picture a predator watchin...">
    <meta property="og:url" content="https://neural-reckoning.org/pub_multisensory-channels-and-time.html">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Fusing multisensory signals across channels and time">
    <meta property="og:description" content="Animals continuously combine information across sensory modalities and time, and use these combined signals to guide their behaviour. Picture a predator watchin...">
    <meta property="og:image" content="https://neural-reckoning.org/default-social-media-card.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta property="twitter:domain" content="neural-reckoning.org">
    <meta property="twitter:url" content="https://neural-reckoning.org/pub_multisensory-channels-and-time.html">
    <meta name="twitter:title" content="Fusing multisensory signals across channels and time">
    <meta name="twitter:description" content="Animals continuously combine information across sensory modalities and time, and use these combined signals to guide their behaviour. Picture a predator watchin...">
    <meta name="twitter:image" content="https://neural-reckoning.org/default-social-media-card.png">
    <meta name="fediverse:creator" content="@neuralreckoning@neuromatch.social"/>
    <!-- bsky embed feed -->
    <script type="module" src="https://cdn.jsdelivr.net/npm/bsky-embed/dist/bsky-embed.es.js" async></script>


    <title>Fusing multisensory signals across channels and time</title>
    <link rel="STYLESHEET" href="style.css" type="text/css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css">

</head>
<body>

<nav class="navbar sticky-top navbar-expand-xl navbar-light bg-light"><div class="container">
    <a class="navbar-brand" href="index.html">
            <img src="nr-logo-small.png" class="img-fluid" style="width: 4em;">
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
                <li class="nav item">
                    <a class="nav-link" href="index.html">Home</a>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarMembersDropdown" role="button"
                       data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">People</a>
        			<div class="dropdown-menu" aria-labelledby="navbarMembersDropdown">
                        <a class="dropdown-item" href="members.html">Everyone</a>
                        <div class="dropdown-divider"></div>
                                    <a class="dropdown-item" href="dan_goodman.html">Dan Goodman</a>
                                <h6 class="dropdown-header">Postdocs and Fellows</h6>
                                    <a class="dropdown-item" href="chu_yang.html">Yang Chu</a>
                                    <a class="dropdown-item" href="danyal_akarca.html">Danyal Akarca</a>
                                    <a class="dropdown-item" href="pengfei_sun.html">Pengfei Sun</a>
                                <h6 class="dropdown-header">PhD students</h6>
                                    <a class="dropdown-item" href="gabriel_bena.html">Gabriel Béna</a>
                                    <a class="dropdown-item" href="greta_horvathova.html">Greta Horvathova</a>
                                    <a class="dropdown-item" href="jatin_sharma.html">Jatin Sharma</a>
                                <h6 class="dropdown-header">Affiliated members</h6>
                                    <a class="dropdown-item" href="marcus_ghosh.html">Marcus Ghosh</a>
                    </div>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="publications.html">Publications</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="software.html">Software</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="themes.html">Themes</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="openings.html">Join us</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="location.html">Location</a>
                </li>
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarMiscDropdown" role="button"
                   data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
                <div class="dropdown-menu" aria-labelledby="navbarMiscDropdown">
                        <a class="dropdown-item" href="videos.html">Videos</a>
                        <a class="dropdown-item" href="organisations.html">Organisations</a>
                        <a class="dropdown-item" href="comp-neuro-resources.html">Computational neuroscience resources</a>
                        <a class="dropdown-item" href="reviewing.html">Ending support for legacy academic publishing</a>
                        <a class="dropdown-item" href="neuroinformatics.html">Neuroinformatics</a>
                        <a class="dropdown-item" href="sensory.html">Sensory neuroscience</a>
                        <a class="dropdown-item" href="mathematics.html">Mathematics</a>
                        <a class="dropdown-item" href="apply_phd.html">PhD application process</a>
                        <a class="dropdown-item" href="accessibility.html">Accessibility statement</a>
                </div>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://neuromatch.social/@neuralreckoning" rel="me"><i class="fa-brands fa-mastodon"></i><span class="d-inline d-xl-none"> Mastodon</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://bsky.app/profile/neural-reckoning.org" rel="me"><i class="fa-brands fa-bluesky"></i><span class="d-inline d-xl-none"> Bluesky</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://twitter.com/neuralreckoning" rel="me"><i class="fa-brands fa-twitter"></i><span class="d-inline d-xl-none"> Twitter</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://github.com/neural-reckoning" rel="me"><i class="fa-brands fa-github"></i><span class="d-inline d-xl-none"> GitHub</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://www.youtube.com/@neuralreckoning" rel="me"><i class="fa-brands fa-youtube"></i><span class="d-inline d-xl-none"> YouTube</span></a>
            </li>
        </ul>
    </div>
</div></nav>

<!-- <div class="hideAfterDeadline alert alert-success" data-deadline="2024-10-01" style="text-align: center">
    <a href="https://www.imperial.ac.uk/jobs/search-jobs/description/index.php?jobId=20479&jobTitle=Research+Associate+in+Computational+Neuroscience%2FNeuroAI%2FNeuromorphic+Systems" style="color: black">We have a postdoctoral position available (deadline Sept 30). Click for details.</a>
</div> -->

<div class="container">

    <p>&nbsp;</p>

<div class="main">

<div class="row">
    <div class="col-lg-4 d-none d-lg-block order-lg-12">
        <div style="height: 90vh; overflow-y: scroll;">
            
            <blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgulazs2y" data-bluesky-cid="bafyreicfpeufz6wqsnhx72cica7lpvcgpppw5s7habhzs35gfqbpdd6xli"><p lang="en">New preprint 🤖🧠🧪! With @swathianil.bsky.social and @marcusghosh.bsky.social.

If you want to get the most out of a multisensory signal, you should take it&#39;s temporal structure into account. But which neural architectures do this best? 🧵👇

www.biorxiv.org/content/10.1...</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neuralreckoning.bsky.social)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgulazs2y?ref_src=embed">2025-01-14T12:57:15.179Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgw3pss2y" data-bluesky-cid="bafyreidweb5jhd5b6sqqbzns4ztpj5z3b4gdgunhgy63ghhg7ygsxmtiae"><p lang="en">In previous work, we found that when multimodal information arrives sparsely in time (e.g. prey hiding from predator), nonlinear fusion of different modalities gives a big improvement over linear fusion.

journals.plos.org/ploscompbiol...</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgw3pss2y?ref_src=embed">2025-01-14T12:57:15.180Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgwh4322y" data-bluesky-cid="bafyreig35a6x5kzdhez7g67fc3seqnh6blnbcn4scsdgjde5266gauadva"><p lang="en">In this paper, we looked at what happens when, in addition to being sparse, information arrives in contiguous bursts (e.g. prey scurrying from hiding spot to hiding spot). In general, the optimal algorithm is computationally intractable, so how far can you get with simple neural architectures?</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgwh4322y?ref_src=embed">2025-01-14T12:57:15.181Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgx32qk2y" data-bluesky-cid="bafyreigqom3gd6wqrprrvtyapqnjp2jxzsbkky244vtdzctkedo6bzun3e"><p lang="en">We compared the performance of linear and nonlinear algorithms that ignore temporal structure to two architectures that can use it. The first just uses a sliding window or fixed length short term memory. The second is a recurrent neural network, which in principle can have a much longer memory.</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgx32qk2y?ref_src=embed">2025-01-14T12:57:15.182Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgxicl22y" data-bluesky-cid="bafyreia33kuzhj65sca65lmd2fw3rlxqyiiwhdl7juy4whoc64twrbt32q"><p lang="en">We were expecting the RNN to hugely outperform the sliding window approach, as it has a potentially longer memory and orders of magnitude more trainable parameters. However, if the bursts of information are not too long, the much simpler network does better.</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgxicl22y?ref_src=embed">2025-01-14T12:57:15.183Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgxup2k2y" data-bluesky-cid="bafyreid7ccuitw3k7d7lrvonyoygzaso6pshqj5ggrjaaqfa4oj3ykqgwa"><p lang="en">They also differ in how they generalise. If you train on one burst length and test on other burst lengths, the sliding window algorithms generalise well to longer bursts than they were trained on, and poorly to shorter bursts. The RNNs simply generalise worse the bigger the difference.</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgxup2k2y?ref_src=embed">2025-01-14T12:57:15.184Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgyders2y" data-bluesky-cid="bafyreie7rxjrcubkikn2f6j3mdtjxikhx6umtcrrfzjmb6644tqvdjcvpi"><p lang="en">When we tested more realistic mixed distributions of burst lengths using either a uniform or naturalistic Lévy flight distribution, the simpler algorithms tended to perform better.</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgyders2y?ref_src=embed">2025-01-14T12:57:15.185Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpcgypcmk2y" data-bluesky-cid="bafyreihgkuky6xut2dth4bojyr4yttz6p2447pminhiyz7ljylxcqtnbpi"><p lang="en">We can&#39;t say there is a single best network, but the simple sliding window network does close to as well or better than the RNN across a wide range of training/testing setups, with RNN outperforming the simpler network when information burst lengths get much longer than the window length.</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgypcmk2y?ref_src=embed">2025-01-14T12:57:15.186Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
<blockquote class="bluesky-embed" data-bluesky-uri="at://did:plc:niqde7rkzo7ua3scet2rzyt7/app.bsky.feed.post/3lfpclblmk22y" data-bluesky-cid="bafyreiaqzhqbwavwrvmatae22yd5zucp5bvktdpobcio3iuuf7um36xequ"><p lang="en">In conclusion:
⭐ a relatively simple modification of classic multisensory algorithms can give rise to substantially better performance in more realistic environments.
⭐ Studying the temporal structure in multisensory environments may help explain multisensory neural architectures.</p>&mdash; <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7?ref_src=embed">Dan Goodman (@neural-reckoning.org)</a> <a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpclblmk22y?ref_src=embed">2025-01-14T12:59:43.041Z</a></blockquote><script async src="https://embed.bsky.app/static/embed.js" charset="utf-8"></script>
        </div>
    </div>
    <div class="col-lg-8 order-lg-1">

<h2>Fusing multisensory signals across channels and time</h2>
    <div class="d-none d-sm-block">
        <ul class="list-inline author-list">
    <li>
        <a href="swathi_anil.html">
        <div><img src="photo_swathi_anil.s.circ.png"/></div>
        <div>Swathi Anil</div>
        </a>
    </li>
    <li>
        <a href="dan_goodman.html">
        <div><img src="photo_dan_goodman.s.circ.png"/></div>
        <div>Dan Goodman</div>
        </a>
    </li>
    <li>
        <a href="marcus_ghosh.html">
        <div><img src="photo_marcus_ghosh.s.circ.png"/></div>
        <div>Marcus Ghosh</div>
        </a>
    </li>
</ul>

    </div>
    <div class="d-block d-sm-none">
        <a href="swathi_anil.html">Anil S</a>, <a href="dan_goodman.html">Goodman DFM</a>, <a href="marcus_ghosh.html">Ghosh M</a>
    </div>
<div>
    <i>PLoS Computational Biology</i>
    <i></i>
    <i></i>
    (2025) <font color="#aaaaaa"> 21(6): e1013125</font>
</div>
<div>
    <a href="http://dx.doi.org/10.1371/journal.pcbi.1013125" style="color: #aaaaaa">doi: 10.1371/journal.pcbi.1013125</a>
</div>
<div>&nbsp;</div>
<h3>Abstract</h3>
<div>Animals continuously combine information across sensory modalities and time, and use these combined signals to guide their behaviour. Picture a predator watching their prey sprint and screech through a field. To date, a range of multisensory algorithms have been proposed to model this process including linear and nonlinear fusion, which combine the inputs from multiple sensory channels via either a sum or nonlinear function. However, many multisensory algorithms treat successive observations independently, and so cannot leverage the temporal structure inherent to naturalistic stimuli. To investigate this, we introduce a novel multisensory task in which we provide the same number of task-relevant signals per trial but vary how this information is presented: from many short bursts to a few long sequences. We demonstrate that multisensory algorithms that treat different time steps as independent, perform sub-optimally on this task. However, simply augmenting these algorithms to integrate across sensory channels and short temporal windows allows them to perform surprisingly well, and comparably to fully recurrent neural networks. Overall, our work: highlights the benefits of fusing multisensory information across channels and time, shows that small increases in circuit/model complexity can lead to significant gains in performance, and provides a novel multisensory task for testing the relevance of this in biological systems.</div>

        <h3 class="pt-3">Links</h3>
        <p>
<button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://doi.org/10.1371/journal.pcbi.1013125"><i class="fa-regular fa-file-lines"></i> Journal (HTML)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://www.biorxiv.org/content/10.1101/2024.12.19.629348v2">Preprint (biorxiv)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://www.biorxiv.org/content/10.1101/2024.12.19.629348v2.full"><i class="fa-regular fa-file-lines"></i> Preprint (HTML)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://www.biorxiv.org/content/10.1101/2024.12.19.629348v2.full.pdf"><i class="fa-regular fa-file-pdf"></i> Preprint (PDF)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://github.com/swathianil/Temporal_Nonlinear_fusion">Code (GitHub)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://bsky.app/profile/did:plc:niqde7rkzo7ua3scet2rzyt7/post/3lfpcgulazs2y"><i class="fa-brands fa-bluesky"></i> Bluesky</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://neuromatch.social/@neuralreckoning/113826859929010069"><i class="fa-brands fa-mastodon"></i> Mastodon</a></button>        </p>
        <h3 class="pt-5 pb-3">Related publications</h3>
                <div class="publication_list">
        <h5 class="hide-if-searching">2024</h5>
        <ul>
                <li id="pub_multimodal">
        <div class="publication_list_text">
            <a href="marcus_ghosh.html">Ghosh M</a>, <a href="gabriel_bena.html">Béna G</a>, Bormuth V, <a href="dan_goodman.html">Goodman DFM</a>
                    (2024)
                <br/>
            <a href="pub_multimodal.html">
                <b>Nonlinear fusion is optimal for a wide class of multisensory tasks.</b><br/>
            </a>
            <i>
                PLoS Computational Biology
                
            </i>
        </div>
            <div class="publication_list_icons">
                
                        <a href="https://twitter.com/neuralreckoning/status/1684525463530528768" target="_blank">
                            <i class="fa-brands fa-twitter"></i>
                        </a>
                        
                        <a href="https://www.biorxiv.org/content/10.1101/2023.07.24.550311v2.full.pdf" target="_blank">
                            <i class="fa-regular fa-file-pdf"></i>
                        </a>
                        
                        <a href="https://neuromatch.social/@neuralreckoning/110785811144218374" target="_blank">
                            <i class="fa-brands fa-mastodon"></i>
                        </a>
                        
                        <a href="https://doi.org/10.1371/journal.pcbi.1012246" target="_blank">
                            <i class="fa-regular fa-file-lines"></i>
                        </a>
                        
            </div>
    </li>

        </ul>
    </div>

    <h3 class="pt-3">Categories</h3>
    <p>
<button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_modelling.html">Modelling</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_multimodal.html">Multimodal</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_neuroscience.html">Neuroscience</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_sensory.html">Sensory</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_spiking.html">Spiking</a></button>    </p>



    <p>&nbsp;</p>

</div>

<!-- Optional JavaScript for Bootstrap -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>

<script type="module">
    import { thingsToDoOnLoad } from './nr.js';
    thingsToDoOnLoad();
</script>

</body>
</html>