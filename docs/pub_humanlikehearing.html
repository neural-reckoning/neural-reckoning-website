<!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <!-- <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
          integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO"
          crossorigin="anonymous"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
    <META http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />
    <meta name="twitter:widgets:csp" content="on">
    <meta name="twitter:dnt" content="on">

    <!-- social media card stuff -->
    <meta name="description" content="Deep neural networks have had considerable success in neuroscience as models of the visual system, and recent work has suggested this may also extend to the aud...">
    <meta property="og:url" content="https://neural-reckoning.org/pub_humanlikehearing.html">
    <meta property="og:type" content="website">
    <meta property="og:title" content="The Psychometrics of Automatic Speech Recognition">
    <meta property="og:description" content="Deep neural networks have had considerable success in neuroscience as models of the visual system, and recent work has suggested this may also extend to the aud...">
    <meta property="og:image" content="https://neural-reckoning.org/default-social-media-card.png">
    <meta name="twitter:card" content="summary_large_image">
    <meta property="twitter:domain" content="neural-reckoning.org">
    <meta property="twitter:url" content="https://neural-reckoning.org/pub_humanlikehearing.html">
    <meta name="twitter:title" content="The Psychometrics of Automatic Speech Recognition">
    <meta name="twitter:description" content="Deep neural networks have had considerable success in neuroscience as models of the visual system, and recent work has suggested this may also extend to the aud...">
    <meta name="twitter:image" content="https://neural-reckoning.org/default-social-media-card.png">
    <meta name="fediverse:creator" content="@neuralreckoning@neuromatch.social"/>

    <title>The Psychometrics of Automatic Speech Recognition</title>
    <link rel="STYLESHEET" href="style.css" type="text/css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css">
    <script lang="javascript">
        function hideAfterDeadline() {
            var now = new Date();
            var elements = document.getElementsByClassName("hideAfterDeadline");
            for (var i = 0; i < elements.length; i++) {
                var deadline = new Date(elements[i].getAttribute("data-deadline"));
                if(now > deadline) {
                    elements[i].style.display = "none";
                }
            }
        }
    </script>
</head>
<body onload="hideAfterDeadline()">

<nav class="navbar sticky-top navbar-expand-xl navbar-light bg-light"><div class="container">
    <a class="navbar-brand" href="index.html">
            <img src="nr-logo-small.png" class="img-fluid" style="width: 4em;">
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
                <li class="nav item">
                    <a class="nav-link" href="index.html">Home</a>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarMembersDropdown" role="button"
                       data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">People</a>
        			<div class="dropdown-menu" aria-labelledby="navbarMembersDropdown">
                        <a class="dropdown-item" href="members.html">Everyone</a>
                        <div class="dropdown-divider"></div>
                                    <a class="dropdown-item" href="dan_goodman.html">Dan Goodman</a>
                                <h6 class="dropdown-header">Postdocs and Fellows</h6>
                                    <a class="dropdown-item" href="marcus_ghosh.html">Marcus Ghosh</a>
                                    <a class="dropdown-item" href="danyal_akarca.html">Danyal Akarca</a>
                                    <a class="dropdown-item" href="pengfei_sun.html">Pengfei Sun</a>
                                <h6 class="dropdown-header">PhD students</h6>
                                    <a class="dropdown-item" href="chu_yang.html">Yang Chu</a>
                                    <a class="dropdown-item" href="gabriel_bena.html">Gabriel BÃ©na</a>
                                    <a class="dropdown-item" href="swathi_anil.html">Swathi Anil</a>
                                    <a class="dropdown-item" href="greta_horvathova.html">Greta Horvathova</a>
                                    <a class="dropdown-item" href="jatin_sharma.html">Jatin Sharma</a>
                    </div>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="publications.html">Publications</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="software.html">Software</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="themes.html">Themes</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="openings.html">Join us</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="location.html">Location</a>
                </li>
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarMiscDropdown" role="button"
                   data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
                <div class="dropdown-menu" aria-labelledby="navbarMiscDropdown">
                        <a class="dropdown-item" href="videos.html">Videos</a>
                        <a class="dropdown-item" href="organisations.html">Organisations</a>
                        <a class="dropdown-item" href="comp-neuro-resources.html">Computational neuroscience resources</a>
                        <a class="dropdown-item" href="reviewing.html">Ending support for legacy academic publishing</a>
                        <a class="dropdown-item" href="neuroinformatics.html">Neuroinformatics</a>
                        <a class="dropdown-item" href="sensory.html">Sensory neuroscience</a>
                        <a class="dropdown-item" href="mathematics.html">Mathematics</a>
                        <a class="dropdown-item" href="apply_phd.html">PhD application process</a>
                        <a class="dropdown-item" href="accessibility.html">Accessibility statement</a>
                </div>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://neuromatch.social/@neuralreckoning" rel="me"><i class="fa-brands fa-mastodon"></i><span class="d-inline d-xl-none"> Mastodon</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://bsky.app/profile/neuralreckoning.bsky.social" rel="me"><i class="fa-brands fa-bluesky"></i><span class="d-inline d-xl-none"> Bluesky</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://twitter.com/neuralreckoning" rel="me"><i class="fa-brands fa-twitter"></i><span class="d-inline d-xl-none"> Twitter</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://github.com/neural-reckoning" rel="me"><i class="fa-brands fa-github"></i><span class="d-inline d-xl-none"> GitHub</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://www.youtube.com/@neuralreckoning" rel="me"><i class="fa-brands fa-youtube"></i><span class="d-inline d-xl-none"> YouTube</span></a>
            </li>
        </ul>
    </div>
</div></nav>

<!-- <div class="hideAfterDeadline alert alert-success" data-deadline="2024-10-01" style="text-align: center">
    <a href="https://www.imperial.ac.uk/jobs/search-jobs/description/index.php?jobId=20479&jobTitle=Research+Associate+in+Computational+Neuroscience%2FNeuroAI%2FNeuromorphic+Systems" style="color: black">We have a postdoctoral position available (deadline Sept 30). Click for details.</a>
</div> -->

<div class="container">

    <p>&nbsp;</p>

<div class="main">

<div class="row">
    <div class="col-lg-4 d-none d-lg-block order-lg-12">
        <div style="height: 90vh; overflow-y: scroll;">
            <blockquote class="twitter-tweet" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Are deep nets good brain models? Psychometric testing of automatic speech recognition systems shows they&#39;re not like humans, yet. Newer ones getting closer, but still ignore important cues.<br><br>Preprint with Lotte Weerts, Stuart Rosen and <a href="https://twitter.com/ClopathLab?ref_src=twsrc%5Etfw">@ClopathLab</a>. <a href="https://t.co/JAdHY9bkzD">https://t.co/JAdHY9bkzD</a><br><br>ð§µð</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704493753479168?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">We&#39;re excited about the huge performance leaps in vision and hearing DNNs, and how they&#39;re being used as models of the visual and auditory system, e.g. <a href="https://twitter.com/JoshHMcDermott?ref_src=twsrc%5Etfw">@JoshHMcDermott</a> (<a href="https://t.co/ZqTxQY9q47">https://t.co/ZqTxQY9q47</a>) and <a href="https://twitter.com/HearingTechLab?ref_src=twsrc%5Etfw">@HearingTechLab</a> (<a href="https://t.co/ueeSHQfE1w">https://t.co/ueeSHQfE1w</a>). But do these models work like people?</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704495909347328?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">TL;DR: Automatic speech recognisers are less robust than people at distorted speech, and seem to use different cues (particularly temporal fine structure and periodicity). The most recent model we tested - <a href="https://twitter.com/facebookai?ref_src=twsrc%5Etfw">@facebookai</a> Wav2Vec - was the closest to humans, and also the best overall</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704498757242887?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">As well as being the best, most robust model, Wav2Vec was also the only end-to-end trained model not using a hand-designed speech recognition front-end (MFCC features). This raises questions about the validity of these front-ends and is a hopeful sign for future developments!</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704500812492800?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">So although current models are not good enough to be used as proxies for the auditory system, we expect this to change as these models improve. We provide our benchmarks as an open source library HumanlikeHearing to make it easy to test future systems:<a href="https://t.co/isnCbhQeZG">https://t.co/isnCbhQeZG</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704502901264389?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Now, let&#39;s get on to some of the gory details. There&#39;s a lot more in the paper if you&#39;re a sucker for punishment. ð</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704505120006146?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">We tested three recent automatic speech recognition (ASR) systems on a range of psychometric tests designed for humans, to compare overall performance, patterns of errors, and work out which auditory cues they were using (think texture vs shape for vision).</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704507162583041?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">The ASR systems we tested were:<br>ð Zurow&#39;s Kaldi nnet3, a DNN-HMM hybrid<br>ð <a href="https://twitter.com/mozilla?ref_src=twsrc%5Etfw">@Mozilla</a> DeepSpeech, based on LSTMs<br>ð <a href="https://twitter.com/facebookai?ref_src=twsrc%5Etfw">@facebookai</a> Wav2Vec, a CNN-Transformer model<br>The first two use a standard speech recognition front-end (MFCCs) while Wav2Vec is trained end-to-end (important ð).</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704509310046208?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">First up: how well do they work with a reduced frequency range? Answer: not well. Humans reach ceiling performance with just 12 semitones around 1.5kHz, while even the best ASR needed around 40. Note that CNN-Transformer did the best here: you&#39;ll see that again. <a href="https://t.co/HHNWPKdduF">pic.twitter.com/HHNWPKdduF</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704513571524616?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Next up: peak and centre clipping. Peak clipping is what happens when your microphone saturates, and centre clipping with some noise suppression systems. ASRs all perform badly with peak clipping, but CNN-Transformer and DNN-HMM match really well for centre clipping. <a href="https://t.co/NgBP4M3Wmg">pic.twitter.com/NgBP4M3Wmg</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704517971304451?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">We looked at how ASR systems use spectral and temporal modulations, following <a href="https://twitter.com/TheunissenLab?ref_src=twsrc%5Etfw">@TheunissenLab</a> method for removing certain modulations. They&#39;re overall less robust (we had to use higher SNR to get comparable results), but seem to be using these modulations in a similar way. <a href="https://t.co/5LoYX7cfkY">pic.twitter.com/5LoYX7cfkY</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704523080052736?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Sounds have slow (envelope) and fast (temporal fine structure) components. TFS has been suggested to be important for hearing in noisy environments. We expected the end-to-end CNN-Transformer might use this better than the systems using MFCCs which mostly discard TFS, but no. <a href="https://t.co/8sgmP1oW4A">pic.twitter.com/8sgmP1oW4A</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704527983108102?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Similarly, none of the ASR systems seem to use periodicity information in the same way as humans. They aren&#39;t as robust to distortion and don&#39;t show the same patterns of errors for different distortions. <a href="https://t.co/KZWkwoEhwG">pic.twitter.com/KZWkwoEhwG</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704533200875532?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">One of the big challenges for both humans and ASR systems is handling competing talkers. Although they perform less well, requiring higher SNRs, the DNN-HMM and CNN-Transformer show a similar pattern to humans, &quot;glimpsing&quot; signals in dips in the noise. <a href="https://t.co/dgnwafnegP">pic.twitter.com/dgnwafnegP</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704537844011014?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Digging deeper into this, humans can benefit from both periodicity and fluctuations in masking noise. Of the ASR systems, only CNN-Transformer shows a benefit from both and a somewhat similar trend. <a href="https://t.co/wRwnqYB0O3">pic.twitter.com/wRwnqYB0O3</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704542172483587?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Finally, you might ask if these comparisons are fair because these models are all trained with clean speech. We fine tuned CNN-Transformer with bandpass filtered speech and it improved performance on that test, but made noise robustness worse. <a href="https://t.co/GBKGVGYmji">pic.twitter.com/GBKGVGYmji</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704546471653377?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">We could probably improve by fine tuning across all our tests, but this isn&#39;t really the point. Most of the distortions we tested are ones that human listeners haven&#39;t previously encountered either.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704548874985474?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">In summary, the ASR systems are quite different to humans, but end-to-end training with CNN-Transformer lets it get a lot closer. If humans are a guide, future models may benefit from making more use of TFS and periodicity information.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704550686855174?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">And if you&#39;ve made it all the way to here, congratulations! We&#39;d love to get feedback on the paper, and if you have a go at using our code, let us know (and file bug reports if you find any!).<br><br>Thank you for reading. ð</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1395704552519839746?ref_src=twsrc%5Etfw">May 21, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
            
        </div>
    </div>
    <div class="col-lg-8 order-lg-1">

<h2>The Psychometrics of Automatic Speech Recognition</h2>
    <div class="d-none d-sm-block">
        <ul class="list-inline author-list">
    <li>
        <a href="lotte_weerts.html">
        <div><img src="photo_lotte_weerts.s.circ.png"/></div>
        <div>Lotte Weerts</div>
        </a>
    </li>
    <li>
        <div><img src="photo_placeholder.s.circ.png"/></div>
        <div>Rosen S</div>
    </li>
    <li>
        <div><img src="photo_placeholder.s.circ.png"/></div>
        <div>Clopath C</div>
    </li>
    <li>
        <a href="dan_goodman.html">
        <div><img src="photo_dan_goodman.s.circ.png"/></div>
        <div>Dan Goodman</div>
        </a>
    </li>
</ul>

    </div>
    <div class="d-block d-sm-none">
        <a href="lotte_weerts.html">Weerts L</a>, Rosen S, Clopath C, <a href="dan_goodman.html">Goodman DFM</a>
    </div>
<div><i>Preprint</i></div>
<div>&nbsp;</div>
<h3>Abstract</h3>
<div>Deep neural networks have had considerable success in neuroscience as models of the visual system, and recent work has suggested this may also extend to the auditory system. We tested the behaviour of a range of state of the art deep learning-based automatic speech recognition systems on a wide collection of manipulated sounds used in standard human psychometric experiments. While some systems showed qualitative agreement with humans in certain tests, in others all tested systems diverged markedly from humans. In particular, all systems used spectral invariance, temporal fine structure and speech periodicity differently from humans. We conclude that despite some promising results, none of the tested automatic speech recognition systems can yet act as a strong proxy for human speech recognition. However, we note that the more recent systems with better performance also tend to better match human results, suggesting that continued cross-fertilisation of ideas between human and automatic speech recognition may be fruitful. Our open source toolbox allows researchers to assess future automatic speech recognition systems or add additional psychoacoustic measures.</div>
<div>&nbsp;</div>
<div class="embed-responsive embed-responsive-16by9">
    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/TnTphoFWsrE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>

        <h3 class="pt-3">Links</h3>
        <p>
<button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://www.biorxiv.org/content/10.1101/2021.04.19.440438v3">Preprint</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://www.biorxiv.org/content/10.1101/2021.04.19.440438v3.full.pdf"><i class="fa-regular fa-file-pdf"></i> Preprint (PDF)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://github.com/neural-reckoning/HumanlikeHearing">Code</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://twitter.com/neuralreckoning/status/1395704493753479168"><i class="fa-brands fa-twitter"></i> Twitter</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://www.youtube.com/watch?v=TnTphoFWsrE"><i class="fa-solid fa-video"></i> Talk by Dan Goodman (video)</a></button>        </p>
        <h3 class="pt-5 pb-3">Related software</h3>
            <div class="d-flex flex-row flex-nowrap" style="overflow-x: auto;">
    <div class="card col-5 col-md-4 p-1 border-0">
        <div class="card-header bg-transparent border-0" style="height: 100px; background-image: url('humanlike-hearing.png'); background-size: contain; background-repeat: no-repeat; background-position: center bottom;">
        </div>
        <div class="card-body p-1 border-0 text-center">
            <p class="card-title"><a href="sw_humanlike_hearing.html">HumanlikeHearing</a></p>
            <p class="card-text">Python package for psychophysical tests of automatic speech recognition systems.</p>
        </div>
    </div>
</div>

        <h3 class="pt-5 pb-3">Related videos</h3>
            <div class="embed-responsive embed-responsive-16by9">
    <iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/TnTphoFWsrE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</div>
<div>
    <ul class="list-group">
        <li class="list-group-item d-flex justify-content-between align-items-center">
    <div>
        <a href="video_psychometrics_asr.html">The Psychometrics of Automatic Speech Recognition</a><br/>
        Talk on applying psychometric testing to automatic speech recognition systems.    
    </div>
    <span>Talk<span style="color: #aaaaaa;"> / 2022</span></span>
</li>

    </ul>
</div>


    <h3 class="pt-3">Categories</h3>
    <p>
<button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_auditory.html">Auditory</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_machinelearning.html">Machine learning</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_modelling.html">Modelling</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_neuroinformatics.html">Neuroinformatics</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_neuroscience.html">Neuroscience</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_sensory.html">Sensory</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_software.html">Software</a></button>    </p>



    <p>&nbsp;</p>

</div>

<!-- Optional JavaScript for Bootstrap -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<!-- <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script> -->
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>

</body>
</html>