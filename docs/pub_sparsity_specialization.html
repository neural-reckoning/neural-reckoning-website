<!doctype html>
<html lang="en">
<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet"
          href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css"
          integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO"
          crossorigin="anonymous">
    <META http-equiv="Content-Type" content="text/html; charset=utf-8"/>
    <meta http-equiv="cache-control" content="max-age=0" />
    <meta http-equiv="cache-control" content="no-cache" />
    <meta http-equiv="expires" content="0" />
    <meta http-equiv="expires" content="Tue, 01 Jan 1980 1:00:00 GMT" />
    <meta http-equiv="pragma" content="no-cache" />
    <meta name="twitter:widgets:csp" content="on">
    <meta name="twitter:dnt" content="on">
    <title>Extreme sparsity gives rise to functional specialization</title>
    <link rel="STYLESHEET" href="style.css" type="text/css"/>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
</head>
<body>

<nav class="navbar sticky-top navbar-expand-xl navbar-light bg-light"><div class="container">
    <a class="navbar-brand" href="index.html">
            <img src="nr-logo-small.png" class="img-fluid" style="width: 4em;">
    </a>
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-nav mr-auto">
                <li class="nav item">
                    <a class="nav-link" href="index.html">Home</a>
                </li>
                <li class="nav-item dropdown">
                    <a class="nav-link dropdown-toggle" href="#" id="navbarMembersDropdown" role="button"
                       data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">People</a>
        			<div class="dropdown-menu" aria-labelledby="navbarMembersDropdown">
                        <a class="dropdown-item" href="members.html">Everyone</a>
                        <div class="dropdown-divider"></div>
                                    <a class="dropdown-item" href="dan_goodman.html">Dan Goodman</a>
                                <h6 class="dropdown-header">Postdocs and Fellows</h6>
                                    <a class="dropdown-item" href="marcus_ghosh.html">Marcus Ghosh</a>
                                <h6 class="dropdown-header">PhD students</h6>
                                    <a class="dropdown-item" href="chu_yang.html">Yang Chu</a>
                                    <a class="dropdown-item" href="nicolas_perez.html">Nicolas Perez</a>
                                    <a class="dropdown-item" href="gabriel_bena.html">Gabriel BÃ©na</a>
                    </div>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="publications.html">Publications</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="software.html">Software</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="themes.html">Themes</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="openings.html">Join us</a>
                </li>
                <li class="nav item">
                    <a class="nav-link" href="location.html">Location</a>
                </li>
            <li class="nav-item dropdown">
                <a class="nav-link dropdown-toggle" href="#" id="navbarMiscDropdown" role="button"
                   data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
                <div class="dropdown-menu" aria-labelledby="navbarMiscDropdown">
                        <a class="dropdown-item" href="videos.html">Videos</a>
                        <a class="dropdown-item" href="organisations.html">Organisations</a>
                        <a class="dropdown-item" href="comp-neuro-resources.html">Computational neuroscience resources</a>
                        <a class="dropdown-item" href="neuroinformatics.html">Neuroinformatics</a>
                        <a class="dropdown-item" href="sensory.html">Sensory neuroscience</a>
                        <a class="dropdown-item" href="mathematics.html">Mathematics</a>
                        <a class="dropdown-item" href="apply_phd.html">PhD application process</a>
                        <a class="dropdown-item" href="accessibility.html">Accessibility statement</a>
                </div>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://twitter.com/neuralreckoning"><i class="fa fa-twitter"></i><span class="d-inline d-xl-none"> Twitter</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://github.com/neural-reckoning"><i class="fa fa-github"></i><span class="d-inline d-xl-none"> GitHub</span></a>
            </li>
            <li class="nav item">
                <a class="nav-link" href="https://www.youtube.com/channel/UCfJdfQGtvv7IN8YAIz4yfGw"><i class="fa fa-youtube-play"></i><span class="d-inline d-xl-none"> YouTube</span></a>
            </li>
        </ul>
    </div>
</div></nav>

<div class="container">

    <p>&nbsp;</p>

<div class="main">

<div class="row">
    <div class="col-lg-4 d-none d-lg-block order-lg-12">
        <div style="height: 90vh; overflow-y: scroll;">
            <blockquote class="twitter-tweet" data-width="400" data-dnt="true"><p lang="en" dir="ltr">New preprint/tweeprint! ðŸ§µðŸ‘‡<br><br>Modularity can be structural (what connects to what) or functional (specialised groups of neurons). Are these related? Yes, but more weakly than you might guess.<br><br>Work by PhD student Gabriel BÃ©na - feedback appreciated!<a href="https://t.co/h70TXa7jFT">https://t.co/h70TXa7jFT</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131198834282499?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">TLDR: enforcing structural modularity in the architecture of a NN trained on a task naturally composed of subtasks leads to module specialisation on subtasks, but only at extreme levels. Even quite high levels of structural modularity lead to no functional specialisation.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131202038804483?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">We looked at the simplest possible case of two modules, each densely connected with sparse connections between them. This lets us precisely control structural modularity from maximum (single interconnect) to no modularity (fully interconnected).</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131206094725125?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Each module gets a separate input MNIST digit. The whole network has to return one or the other of the digits depending on whether two digit parities same or different. This forces modules to share some info, but allows for specialisation on subtask of classifying each digit.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131209311756290?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Now the tricky part: how do we measure whether or not the modules have specialised? This is a surprisingly complicated question - see the replies in this thread: <a href="https://t.co/vS89qj08xy">https://t.co/vS89qj08xy</a><br><br>Thanks to everyone who replied in that thread - your ideas really helped!</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131212386152449?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">We couldn&#39;t find a single satisfactory answer, so we tried three separate measures of functional specialisation (based on informational bottleneck, weight masks, correlation). Fortunately, they all qualitatively agreed in this case, so it seems they are measuring something real.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131216572006404?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Results: functional specialisation increases monotonically with structural modularity Q, but only becomes substantial when Q is close to max (Q=0.5). If there are more than a handful of connections between modules, they become functionally entangled. <a href="https://t.co/MFAKV3WAoN">pic.twitter.com/MFAKV3WAoN</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131225854005256?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">So what&#39;s the take home message here? Firstly, it&#39;s great that these three very different measures broadly agree. Secondly, if you&#39;re looking to use structural modularity as a proxy for functional modularity, beware! You only get that at extreme levels.</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131229834383364?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">For reference, a network with a structural modularity Q=0.35 is usually described as &quot;highly modular&quot;, but in all of our measures doesn&#39;t give rise to much functional specialisation at all. Does this pose problems for the connectomics project?</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131232812408832?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">One thing we&#39;d like to look into in future is how this changes when the number of bits of information that the modules need to share changes. In our task, they only need to share one bit.<br><br>Any other ideas or comments/questions?<br><br>Thanks for reading!</p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131235496767496?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<blockquote class="twitter-tweet" data-conversation="none" data-width="400" data-dnt="true"><p lang="en" dir="ltr">Also, I&#39;m using this as an opportunity to share the &quot;notpaper&quot; version of this preprint. It&#39;s an experimental new way of reading papers I&#39;m working on as a side project. Would be interested in feedback on this too - do you find it helpful?<a href="https://t.co/zx5ifDT3do">https://t.co/zx5ifDT3do</a></p>&mdash; Dan Goodman (@neuralreckoning) <a href="https://twitter.com/neuralreckoning/status/1405131238160179201?ref_src=twsrc%5Etfw">June 16, 2021</a></blockquote>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>

        </div>
    </div>
    <div class="col-lg-8 order-lg-1">

<h2>Extreme sparsity gives rise to functional specialization</h2>
    <div class="d-none d-sm-block">
        <ul class="list-inline author-list">
    <li>
        <a href="gabriel_bena.html">
        <div><img src="photo_gabriel_bena.s.circ.png"/></div>
        <div>Gabriel BÃ©na</div>
        </a>
    </li>
    <li>
        <a href="dan_goodman.html">
        <div><img src="photo_dan_goodman.s.circ.png"/></div>
        <div>Dan Goodman</div>
        </a>
    </li>
</ul>

    </div>
    <div class="d-block d-sm-none">
        <a href="gabriel_bena.html">BÃ©na G</a>, <a href="dan_goodman.html">Goodman DFM</a>
    </div>
<div><i>Preprint</i></div>
<div>&nbsp;</div>
<h3>Abstract</h3>
<div>Modularity of neural networks â€“ both biological and artificial â€“ can be thought of either structurally or functionally, and the relationship between these is an open question. We show that enforcing structural modularity via sparse connectivity between two dense sub-networks which need to communicate to solve the task leads to functional specialization of the sub-networks, but only at extreme levels of sparsity. With even a moderate number of interconnections, the sub-networks become functionally entangled. Defining functional specialization is in itself a challenging problem without a universally agreed solution. To address this, we designed three different measures of specialization (based on weight masks, retraining and correlation) and found them to qualitatively agree. Our results have implications in both neuroscience and machine learning. For neuroscience, it shows that we cannot conclude that there is functional modularity simply by observing moderate levels of structural modularity: knowing the brainâ€™s connectome is not sufficient for understanding how it breaks down into functional modules. For machine learning, using structure to promote functional modularity â€“ which may be important for robustness and generalization â€“ may require extremely narrow bottlenecks between modules.</div>

        <h3 class="pt-3">Links</h3>
        <p>
<button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://arxiv.org/abs/2106.02626">Preprint</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://arxiv.org/pdf/2106.02626"><i class="fa fa-file-pdf-o"></i> Preprint (PDF)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://neural-reckoning.github.io/preprints/sparsity-specialization/"><i class="fa fa-newspaper-o"></i> Preprint (HTML)</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="https://twitter.com/neuralreckoning/status/1405131198834282499"><i class="fa fa-twitter"></i> Twitter</a></button>        </p>
    <h3 class="pt-3">Categories</h3>
    <p>
<button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_learning.html">Learning</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_machinelearning.html">Machine learning</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_modelling.html">Modelling</a></button><button type="button" class="btn btn-light" style="margin: 2px;"><a href="publication_category_neuroscience.html">Neuroscience</a></button>    </p>



    <p>&nbsp;</p>

</div>

<!-- Optional JavaScript for Bootstrap -->
<!-- jQuery first, then Popper.js, then Bootstrap JS -->
<script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>

</body>
</html>